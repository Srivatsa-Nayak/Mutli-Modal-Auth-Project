{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b3d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py (from -r requirement.txt (line 1))\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astor (from -r requirement.txt (line 2))\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: backcall in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 4)) (5.1.1)\n",
      "Collecting gast (from -r requirement.txt (line 5))\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta (from -r requirement.txt (line 6))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio (from -r requirement.txt (line 7))\n",
      "  Using cached grpcio-1.54.0-cp38-cp38-win_amd64.whl (4.1 MB)\n",
      "Collecting h5py (from -r requirement.txt (line 8))\n",
      "  Using cached h5py-3.8.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: ipython in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 9)) (8.12.1)\n",
      "Collecting ipython-genutils (from -r requirement.txt (line 10))\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: jedi in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 11)) (0.18.2)\n",
      "Collecting Keras (from -r requirement.txt (line 12))\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting Keras-Applications (from -r requirement.txt (line 13))\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting Keras-Preprocessing (from -r requirement.txt (line 14))\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting Markdown (from -r requirement.txt (line 15))\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting numpy (from -r requirement.txt (line 16))\n",
      "  Using cached numpy-1.24.3-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting opencv-python (from -r requirement.txt (line 17))\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Requirement already satisfied: parso in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 18)) (0.8.3)\n",
      "Collecting pexpect (from -r requirement.txt (line 19))\n",
      "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 20)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 21)) (3.0.38)\n",
      "Collecting protobuf (from -r requirement.txt (line 22))\n",
      "  Using cached protobuf-4.22.3-cp38-cp38-win_amd64.whl (420 kB)\n",
      "Collecting ptyprocess (from -r requirement.txt (line 23))\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting PyAudio (from -r requirement.txt (line 24))\n",
      "  Using cached PyAudio-0.2.13-cp38-cp38-win_amd64.whl (164 kB)\n",
      "Requirement already satisfied: Pygments in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 25)) (2.15.1)\n",
      "Collecting python-speech-features (from -r requirement.txt (line 26))\n",
      "  Using cached python_speech_features-0.6-py3-none-any.whl\n",
      "Collecting PyYAML (from -r requirement.txt (line 27))\n",
      "  Using cached PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Collecting scikit-learn (from -r requirement.txt (line 28))\n",
      "  Using cached scikit_learn-1.2.2-cp38-cp38-win_amd64.whl (8.3 MB)\n",
      "Collecting scipy (from -r requirement.txt (line 29))\n",
      "  Using cached scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 30)) (1.16.0)\n",
      "Collecting tensorboard (from -r requirement.txt (line 31))\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow (from -r requirement.txt (line 32))\n",
      "  Using cached tensorflow-2.12.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-estimator (from -r requirement.txt (line 33))\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting termcolor (from -r requirement.txt (line 34))\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: traitlets in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 35)) (5.9.0)\n",
      "Collecting Wave (from -r requirement.txt (line 36))\n",
      "  Using cached Wave-0.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: wcwidth in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from -r requirement.txt (line 37)) (0.2.6)\n",
      "Collecting Werkzeug (from -r requirement.txt (line 38))\n",
      "  Using cached Werkzeug-2.3.3-py3-none-any.whl (242 kB)\n",
      "Collecting wrapt (from -r requirement.txt (line 39))\n",
      "  Using cached wrapt-1.15.0-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from ipython->-r requirement.txt (line 9)) (0.1.6)\n",
      "Requirement already satisfied: stack-data in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from ipython->-r requirement.txt (line 9)) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from ipython->-r requirement.txt (line 9)) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from ipython->-r requirement.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from Markdown->-r requirement.txt (line 15)) (6.6.0)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn->-r requirement.txt (line 28))\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirement.txt (line 28))\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached requests-2.29.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from tensorboard->-r requirement.txt (line 31)) (67.7.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from tensorboard->-r requirement.txt (line 31)) (0.40.0)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached tensorflow_intel-2.12.0-cp38-cp38-win_amd64.whl (272.8 MB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast (from -r requirement.txt (line 5))\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting jax>=0.3.15 (from tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached jax-0.4.8-py3-none-any.whl\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting numpy (from -r requirement.txt (line 16))\n",
      "  Using cached numpy-1.23.5-cp38-cp38-win_amd64.whl (14.7 MB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32)) (23.1)\n",
      "Collecting wrapt (from -r requirement.txt (line 39))\n",
      "  Using cached wrapt-1.14.1-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting MarkupSafe>=2.1.1 (from Werkzeug->-r requirement.txt (line 38))\n",
      "  Using cached MarkupSafe-2.1.2-cp38-cp38-win_amd64.whl (16 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from importlib-metadata>=4.4->Markdown->-r requirement.txt (line 15)) (3.15.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached charset_normalizer-3.1.0-cp38-cp38-win_amd64.whl (96 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests<3,>=2.21.0->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from stack-data->ipython->-r requirement.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from stack-data->ipython->-r requirement.txt (line 9)) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\swaro\\onedrive\\documents\\fproject\\venv\\lib\\site-packages (from stack-data->ipython->-r requirement.txt (line 9)) (0.2.2)\n",
      "Collecting ml-dtypes>=0.0.3 (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow->-r requirement.txt (line 32))\n",
      "  Using cached ml_dtypes-0.1.0-cp38-cp38-win_amd64.whl (120 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirement.txt (line 31))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: Wave, tensorboard-plugin-wit, python-speech-features, PyAudio, ptyprocess, libclang, ipython-genutils, flatbuffers, wrapt, urllib3, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, PyYAML, pyasn1, protobuf, pexpect, oauthlib, numpy, MarkupSafe, Keras, joblib, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, astunparse, astor, absl-py, Werkzeug, scipy, rsa, requests, pyasn1-modules, opt-einsum, opencv-python, ml-dtypes, Markdown, Keras-Preprocessing, h5py, scikit-learn, requests-oauthlib, Keras-Applications, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed Keras-2.12.0 Keras-Applications-1.0.8 Keras-Preprocessing-1.1.2 Markdown-3.4.3 MarkupSafe-2.1.2 PyAudio-0.2.13 PyYAML-6.0 Wave-0.0.2 Werkzeug-2.3.3 absl-py-1.4.0 astor-0.8.1 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 h5py-3.8.0 idna-3.4 ipython-genutils-0.2.0 jax-0.4.8 joblib-1.2.0 libclang-16.0.0 ml-dtypes-0.1.0 numpy-1.23.5 oauthlib-3.2.2 opencv-python-4.7.0.72 opt-einsum-3.3.0 pexpect-4.8.0 protobuf-4.22.3 ptyprocess-0.7.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 python-speech-features-0.6 requests-2.29.0 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.2.2 scipy-1.10.1 tensorboard-2.12.2 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 threadpoolctl-3.1.0 urllib3-1.26.15 wrapt-1.14.1\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirement.txt\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88134c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pyaudio\n",
    "import time\n",
    "from numpy import genfromtxt\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import sys\n",
    "    \n",
    "K.set_image_data_format('channels_first')\n",
    "# np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import pyaudio\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "# from sklearn.mixture import GMM \n",
    "# from sklearn import mixture\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# for converting audio to mfcc\n",
    "import python_speech_features as mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f80f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows -1:\n",
    "                second = rows -1\n",
    "            else:\n",
    "                second = i+j\n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "\n",
    "#convert audio to mfcc features\n",
    "def extract_features(audio,rate):    \n",
    "    mfcc_feat = mfcc.mfcc(audio,rate, 0.025, 0.01,20,appendEnergy = True, nfft=1400)\n",
    "    mfcc_feat = preprocessing.scale(mfcc_feat)\n",
    "    delta = calculate_delta(mfcc_feat)\n",
    "\n",
    "    #combining both mfcc features and delta\n",
    "    combined = np.hstack((mfcc_feat,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6607b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user():\n",
    "    \n",
    "    name = input(\"Enter Name:\")\n",
    "     # check for existing database\n",
    "    if os.path.exists('./voice_database/embeddings.pickle'):\n",
    "        with open('./voice_database/embeddings.pickle', 'rb') as database:\n",
    "            db = pickle.load(database)   \n",
    "            \n",
    "            if name in db:\n",
    "                print(\"Name Already Exists! Try Another Name...\")\n",
    "                return\n",
    "    else:\n",
    "        #if database not exists than creating new database\n",
    "        db = {}\n",
    "\n",
    "\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 10\n",
    "\n",
    "    source = \"./voice_database/\" + name\n",
    "\n",
    "\n",
    "    os.mkdir(source)\n",
    "\n",
    "    for i in range(3):\n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        if i == 0:\n",
    "            j = 3\n",
    "            while j>=0:\n",
    "                time.sleep(1.0)\n",
    "                print(\"Speak your Aadhar number in {} seconds\".format(j))\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                j-=1\n",
    "\n",
    "        elif i ==1:\n",
    "            print(\"One more time\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        else:\n",
    "            print(\"One last time\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        # start Recording\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "        print(\"recording...\")\n",
    "        frames = []\n",
    "\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "        # stop Recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "        # saving wav file of speaker\n",
    "        waveFile = wave.open(source + '/' + str((i+1)) + '.wav', 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        print(\"Done\")\n",
    "\n",
    "    dest =  \"./gmm_models/\"\n",
    "    count = 1\n",
    "\n",
    "    for path in os.listdir(source):\n",
    "        path = os.path.join(source, path)\n",
    "\n",
    "        features = np.array([])\n",
    "\n",
    "        # reading audio files of speaker\n",
    "        (sr, audio) = read(path)\n",
    "\n",
    "        # extract 40 dimensional MFCC & delta MFCC features\n",
    "        vector   = extract_features(audio,sr)\n",
    "\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "\n",
    "        # when features of 3 files of speaker are concatenated, then do model training\n",
    "        if count == 3:    \n",
    "            gmm = GMM(n_components = 16, max_iter=200,covariance_type='diag',n_init = 33)\n",
    "            gmm.fit(features)\n",
    "\n",
    "            # saving the trained gaussian model\n",
    "            pickle.dump(gmm, open(dest + name + '.GMM', 'wb'))\n",
    "            print(name + ' added successfully') \n",
    "\n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f0b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "*\n",
      "unknown_test added successfully\n"
     ]
    }
   ],
   "source": [
    "name = 'unknown_test'\n",
    "dest =  \"./gmm_models/\"\n",
    "count = 1\n",
    "source = \"./voice_database/\" + name\n",
    "\n",
    "for path in os.listdir(source):\n",
    "        path = os.path.join(source, path)\n",
    "\n",
    "        features = np.array([])\n",
    "\n",
    "        # reading audio files of speaker\n",
    "        (sr, audio) = read(path)\n",
    "        \n",
    "\n",
    "        # extract 40 dimensional MFCC & delta MFCC features\n",
    "        vector   = extract_features(audio,sr)\n",
    "        print(count)\n",
    "\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "\n",
    "        # when features of 3 files of speaker are concatenated, then do model training\n",
    "        if count == 33:    \n",
    "            gmm = GMM(n_components = 16, max_iter=200,covariance_type='diag',n_init = 33)\n",
    "            gmm.fit(features)\n",
    "            print('*')\n",
    "\n",
    "            # saving the trained gaussian model\n",
    "            \n",
    "            pickle.dump(gmm, open(dest + name + '.GMM', 'wb'))\n",
    "            print(name + ' added successfully') \n",
    "\n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab23bfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "Done\n",
      "One more time\n",
      "recording...\n",
      "Done\n",
      "One last time\n",
      "recording...\n",
      "Done\n",
      "Swaroop added successfully\n"
     ]
    }
   ],
   "source": [
    "add_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936a382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize():\n",
    "    # Voice Authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 10\n",
    "    FILENAME = \"./test.wav\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    # saving wav file \n",
    "    waveFile = wave.open(FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "    modelpath = \"./gmm_models/\"\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "                os.listdir(modelpath) if fname.endswith('.GMM')]\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "    speakers   = [fname.split(\"/\")[-1].split(\".GMM\")[0] for fname \n",
    "                in gmm_files]\n",
    "    \n",
    "    if len(models) == 0:\n",
    "        print(\"No Users Authorized!\")\n",
    "        return\n",
    "        \n",
    "    #read test file\n",
    "    sr,audio = read(FILENAME)\n",
    "    # extract mfcc features\n",
    "    vector = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    #checking with each model one by one\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]         \n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "    \n",
    "    pred = np.argmax(log_likelihood)\n",
    "    print(pred)\n",
    "    print(speakers)\n",
    "    identity = speakers[pred]\n",
    "    print(identity)\n",
    "    print(log_likelihood)\n",
    "    # if voice not recognized than terminate the process\n",
    "#     print(speakers)\n",
    "    if identity == 'unknown_test' and 'unknown':\n",
    "        print(\"Not Recognized! Try again...\")\n",
    "    elif identity == 'blank':\n",
    "        print(\"No voice detected!\")\n",
    "    else:\n",
    "        print( \"Recognized as - \", identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe8b1e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "finished recording\n",
      "6\n",
      "['anushka', 'blank', 'jaya maam', 'new2', 'shwetha maam', 'srivatsa', 'Swaroop', 'unknown', 'unknown_test']\n",
      "Swaroop\n",
      "[-22.94055675 -28.69480969 -24.93155755 -21.8854966  -24.80655784\n",
      " -24.97940369 -19.11337366 -51.78340956 -22.19023216]\n",
      "Recognized as -  Swaroop\n"
     ]
    }
   ],
   "source": [
    "recognize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad316f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e2605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
